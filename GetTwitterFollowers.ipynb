{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GetTwitterFollowers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRg64MKYbtenTut9ssBHFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vplata/Twitter/blob/master/GetTwitterFollowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLwpzFubTiVS",
        "colab_type": "text"
      },
      "source": [
        "Recopilacion de datos de Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj5bICNJThU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all needed libraries\n",
        "import tweepy                   # Python wrapper around Twitter API\n",
        "from google.colab import drive  # to mount Drive to Colab notebook\n",
        "import json\n",
        "import csv\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXIIkFyLULVF",
        "colab_type": "text"
      },
      "source": [
        "Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n831WrISUQ4P",
        "colab_type": "code",
        "outputId": "3d882c55-ba01-4380-c954-e61cd20817c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Connect Google Drive to Colab\n",
        "drive.mount('/content/gdrive')\n",
        "# Create a variable to store the data path on your drive\n",
        "path = './gdrive/My Drive/TwitterStats/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4tOvTy9Urmy",
        "colab_type": "text"
      },
      "source": [
        "Autenticate to Twitter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zi1d473Uv2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Twitter API secrets from an external JSON file\n",
        "# secrets = json.loads(open(path + 'secrets.json').read())\n",
        "api_key = 'q1Rg0DBMKvSVTuN6Mg7THOwpA'\n",
        "api_secret_key = 'Rx02PN0W2a67LcBMIHHJ3PJKOk28OwjRxefVgC9Jvm7M6a7LNl'\n",
        "access_token = '104981578-AduHmI3pWtWC6atjmr59pF1xYthQcfr1IjnE4ISO'\n",
        "access_token_secret = 'OdMvlbcV3mmeMP7fzmDpP0bWRxcPNkSizNo7EDDVPhIaY'\n",
        "# Connect to Twitter API using the secrets\n",
        "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRzEQSwsQGoX",
        "colab_type": "text"
      },
      "source": [
        "Save JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmEvuu6lQKQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_json(file_name, file_content):\n",
        "  with open(path + file_name, 'w', encoding='utf-8') as f:\n",
        "    json.dump(file_content, f, ensure_ascii=False, indent=4)\n",
        "    print(path + file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJKKbHfRW1NR",
        "colab_type": "text"
      },
      "source": [
        "Handle rate limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDroSQ4yW5Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to handle twitter API rate limit\n",
        "def limit_handled(cursor, list_name):\n",
        "  while True:\n",
        "    try:\n",
        "      yield cursor.next()\n",
        "    # Catch Twitter API rate limit exception and wait for 15 minutes\n",
        "    except tweepy.RateLimitError:\n",
        "      print(\"\\nData points in list = {}\".format(len(list_name)))\n",
        "      print('Hit Twitter API rate limit.')\n",
        "      for i in range(3, 0, -1):\n",
        "        print(\"Wait for {} mins.\".format(i * 5))\n",
        "        time.sleep(5 * 60)\n",
        "    # Catch any other Twitter API exceptions\n",
        "    except tweepy.error.TweepError:\n",
        "      print('\\nCaught TweepError exception' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWNV6rDxHOO8",
        "colab_type": "text"
      },
      "source": [
        "Get all twitts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSgXUbGWHU4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to get all tweets of a specified user\n",
        "# NOTE:This method only allows access to the most recent 3200 tweets\n",
        "# Source: https://gist.github.com/yanofsky/5436496\n",
        "def get_all_tweets(screen_name):\n",
        "\n",
        "  # initialize a list to hold all the Tweets\n",
        "  alltweets = []\n",
        "  # make initial request for most recent tweets \n",
        "  # (200 is the maximum allowed count)\n",
        "  new_tweets = api.user_timeline(screen_name = screen_name,count=page_size)\n",
        "  # save most recent tweets\n",
        "  alltweets.extend(new_tweets)\n",
        "  # save the id of the oldest tweet less one to avoid duplication\n",
        "  oldest = alltweets[-1].id - 1\n",
        "  # keep grabbing tweets until there are no tweets left\n",
        "  while len(new_tweets) > 0:\n",
        "    print(\"getting tweets before %s\" % (oldest))\n",
        "    # all subsequent requests use the max_id param to prevent\n",
        "    # duplicates\n",
        "    new_tweets = api.user_timeline(screen_name = screen_name,count=page_size,max_id=oldest)\n",
        "    # save most recent tweets\n",
        "    alltweets.extend(new_tweets)\n",
        "    # update the id of the oldest tweet less one\n",
        "    oldest = alltweets[-1].id - 1\n",
        "    print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
        "    ### END OF WHILE LOOP ###\n",
        "  # transform the tweepy tweets into a 2D array that will \n",
        "  # populate the csv\n",
        "  outtweets = [[tweet.id_str, tweet.created_at, tweet.text, tweet.favorite_count,tweet.in_reply_to_screen_name, tweet.retweeted] for tweet in alltweets]\n",
        "  # write the csv\n",
        "  with open(path + '%s_tweets.csv' % screen_name, 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"id\",\"created_at\",\"text\",\"likes\",\"in reply to\",\"retweeted\"])\n",
        "    writer.writerows(outtweets)\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFb1gah5XG97",
        "colab_type": "text"
      },
      "source": [
        "Followers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGXCxfHVXI6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to save follower objects in a JSON file.\n",
        "def get_followers(screen_name):\n",
        "  \n",
        "  # Create a list to store follower data\n",
        "  followers_list = []\n",
        "  # For-loop to iterate over tweepy cursors\n",
        "  cursor = tweepy.Cursor(api.followers, screen_name=screen_name, count=page_size).pages(num_pages)\n",
        "  for i, page in enumerate(limit_handled(cursor, followers_list)):  \n",
        "    print(\"\\r\"+\"Loading\"+ i % 5 *\".\", end='')\n",
        "    \n",
        "    # Add latest batch of follower data to the list\n",
        "    followers_list += page\n",
        "  \n",
        "  # Extract the follower information\n",
        "  followers_list = [x._json for x in followers_list]\n",
        "  # Save the data in a JSON file\n",
        "  save_json((screen_name+'_followers_data.json'), followers_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AChPlZvPXSgF",
        "colab_type": "text"
      },
      "source": [
        "Following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1rxt9z1XVRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to save friend objects in a JSON file.\n",
        "def get_friends(screen_name):\n",
        "  \n",
        "  # Create a list to store friends data\n",
        "  friends_list = []\n",
        "  # For-loop to iterate over tweepy cursors\n",
        "  cursor = tweepy.Cursor(api.friends, screen_name=screen_name, count=page_size).pages(num_pages)\n",
        "  for i, page in enumerate(limit_handled(cursor, friends_list)):  \n",
        "    print(\"\\r\"+\"Loading\"+ i % 5 *\".\", end='')\n",
        "    \n",
        "    # Add latest batch of friend data to the list\n",
        "    friends_list += page\n",
        "  \n",
        "  # Extract the friends information\n",
        "  friends_list = [x._json for x in friends_list]\n",
        "  # Save the data in a JSON file\n",
        "  save_json((screen_name+'_friends_data.json'), friends_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6-48d6wXdHb",
        "colab_type": "text"
      },
      "source": [
        "Todays Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vWPbew1Xfc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to save daily follower and following counts in a JSON file\n",
        "this_dict = {}\n",
        "\n",
        "def todays_stats(dict_name, screen_name):\n",
        "  \n",
        "  # Get my account information\n",
        "  #info = api.me()\n",
        "  info = api.get_user(screen_name)\n",
        "  # Get follower and following counts\n",
        "  followers_cnt = info.followers_count  \n",
        "  following_cnt = info.friends_count\n",
        "  # Get today's date\n",
        "  today = date.today()\n",
        "  d = today.strftime(\"%b %d, %Y\")\n",
        "  # Save today's stats only if they haven't been collected before\n",
        "  if d not in dict_name:\n",
        "    dict_name[d] = {\"followers\":followers_cnt, \"following\":following_cnt}\n",
        "    save_json((screen_name+\"_follower_history.json\"), dict_name)\n",
        "  else:\n",
        "    print('Today\\'s stats already exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFTXrFbyACPc",
        "colab_type": "text"
      },
      "source": [
        "Call Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sej5i6E5ALjn",
        "colab_type": "code",
        "outputId": "5bcb3ba8-215c-4a91-f2df-93d32937cd1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Set parameters\n",
        "user = 'txmglobal'\n",
        "page_size = 200\n",
        "num_pages = 20\n",
        "\n",
        "#Call functions\n",
        "get_all_tweets(user)\n",
        "get_followers(user)\n",
        "get_friends(user)\n",
        "todays_stats(this_dict, user)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting tweets before 748196030408056831\n",
            "...171 tweets downloaded so far\n",
            "Loading./gdrive/My Drive/TwitterStats/txmglobal_followers_data.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: generator 'limit_handled' raised StopIteration\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading../gdrive/My Drive/TwitterStats/txmglobal_friends_data.json\n",
            "./gdrive/My Drive/TwitterStats/txmglobal_follower_history.json\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}